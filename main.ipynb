{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import ast\n",
    "import openai\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import dotenv\n",
    "dotenv.load_dotenv('.env')\n",
    "from scipy.spatial.distance import cosine as cosine_dist_scipy\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosine_sim_sklearn\n",
    "\n",
    "def recursive_knowledge(path: str, node: ast.Module): \n",
    "    sub_df = pd.DataFrame([[path, ast.unparse(node), []]], columns=['path', 'data', 'embedding']) \n",
    "    if not hasattr(node, 'body'): return\n",
    "    for item in node.body:\n",
    "        newPath = path + '>' + item.__class__.__name__\n",
    "        sub_df = pd.concat([sub_df, recursive_knowledge(newPath, item)])\n",
    "    return sub_df\n",
    "        \n",
    "def walk_file_tree(path, ext):\n",
    "    knowledge_df = pd.DataFrame(columns=['path', 'data', 'embedding'])\n",
    "    for item in os.listdir(path):\n",
    "        item_path = os.path.join(path, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            knowledge_df = pd.concat([knowledge_df, walk_file_tree(item_path, ext)])\n",
    "        elif os.path.splitext(item_path)[1] in ext:\n",
    "            with open(item_path, 'r') as f:\n",
    "                knowledge_df = pd.concat([knowledge_df, recursive_knowledge(item_path, ast.parse(f.read()))])\n",
    "    return knowledge_df\n",
    "\n",
    "def get_embeddings_oai(texts):\n",
    "    response = openai.embeddings.create(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        input=texts,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def load_knowledge(path_in):\n",
    "    knowledge_df = pd.read_csv(path_in)\n",
    "    knowledge_df['embedding'] = knowledge_df['embedding'].apply(lambda x: json.loads(x))\n",
    "    return knowledge_df\n",
    "\n",
    "def get_repo_name(repo_url):\n",
    "    splt1 = repo_url.split('/')\n",
    "    splt2 = splt1[-1].split('.')\n",
    "    if len(splt2) > 1:\n",
    "        return splt2[0]\n",
    "    else:\n",
    "        return splt1[-1]\n",
    "\n",
    "def wipe_input_dir():\n",
    "    shutil.rmtree('codebase_input', ignore_errors=True)\n",
    "    os.mkdir('codebase_input')\n",
    "\n",
    "def clone_repo(repo_url):\n",
    "    os.system(\"git clone \" + repo_url + \" codebase_input/\" + get_repo_name(repo_url))\n",
    "\n",
    "def generate_knowledge_from_dir(path_in, path_out, ext=['.py']):\n",
    "    knowledge_df = walk_file_tree(path_in, ext)\n",
    "    resp = get_embeddings_oai((\"DATA_PATH: \"+knowledge_df['path']+'\\nDATA:'+knowledge_df['data']).tolist())\n",
    "    resp = [emb.embedding for emb in resp.data]\n",
    "    knowledge_df['embedding'] = resp\n",
    "    knowledge_df.to_csv(path_out, index=False)\n",
    "\n",
    "def reset_codebase(repos, path_out='knowledge_df.csv', ext=['.py']):\n",
    "    #wipe_input_dir()\n",
    "    #for repo in repos:\n",
    "    #    clone_repo(repo)\n",
    "    generate_knowledge_from_dir('codebase_input', path_out, ext)\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "def get_top_k_context(knowledge_df, text, k):\n",
    "    embedding = get_embeddings_oai(text).data[0].embedding\n",
    "    #knowledge_df['similarity'] = knowledge_df['embedding'].apply(lambda x: cosine_similarity(x, embedding))\n",
    "    #knowledge_df['similarity'] = knowledge_df['embedding'].apply(lambda x: 1-cosine_dist_scipy(x, embedding)\n",
    "    knowledge_df['similarity'] = knowledge_df['embedding'].apply(lambda x: cosine_similarity(x, embedding))\n",
    "    return knowledge_df.sort_values(by='similarity', ascending=False).head(k)\n",
    "\n",
    "def train_of_thought(texts,k,i=0):\n",
    "    if k>0:\n",
    "        longtxt = \"\".join(texts)\n",
    "        ctx = get_top_k_context(longtxt, i+1)\n",
    "        texts.append(\"\\nContext: \"+ctx['path'].iloc[i] + \" Data: \" + ctx['data'].iloc[i])\n",
    "        return train_of_thought(texts, k-1, i+1)\n",
    "    else:\n",
    "        return \"\".join(texts)\n",
    "    \n",
    "def ask_assistant(query, ctx, client:openai.OpenAI, thread):\n",
    "    #use context as system messages\n",
    "    ctx_messages = \"\\n\".join((\"CONTEXT:\\nPath: \"+ctx['path']+ \"\\nData: \" + ctx['data']+\"\\n\").tolist())\n",
    "    message = ctx_messages + \"\\nUSER: \" + query\n",
    "    client.beta.threads.messages.create(thread_id=thread.id, content=message,role='user')\n",
    "\n",
    "def handle_user_query(\n",
    "        query,\n",
    "        knowledge_df,\n",
    "        client:openai.OpenAI,\n",
    "        thread,\n",
    "        k=8,\n",
    "):\n",
    "    print(\"assembling context\")\n",
    "    ctx = get_top_k_context(knowledge_df, query, k)\n",
    "    print(\"adding question to assistant thread\")\n",
    "    ask_assistant(query, ctx, client, thread)\n",
    "    print(\"telling assistant to think\")\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=os.getenv('OPENAI_ASSISTANT_ID')\n",
    "    )\n",
    "    print(\"waiting for assistant to respond\")\n",
    "    sec=0\n",
    "    while run.status != 'completed':\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        time.sleep(1)\n",
    "        #print with carriage return that the program is still waiting\n",
    "        print(f\"Waiting...{sec}\", end='\\r')\n",
    "        sec+=1\n",
    "    print(\"assistant responded\")\n",
    "    response = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = [\n",
    "    \"https://github.com/mobutu/ecf-srdf-service-orchestrator\",\n",
    "    \"https://github.com/mobutu/ecf-srdf-service-file-to-image\",\n",
    "    \"https://github.com/Deathtanium/ecf-srdf-service-image-optimizer/\",\n",
    "    \"https://github.com/mobutu/ecf-srdf-service-iocr\",\n",
    "    \"https://github.com/mobutu/ecf-srdf-service-file-classifier\",\n",
    "    \"https://github.com/mobutu/ecf-srdf-service-details-extractor\"\n",
    "]\n",
    "reset_codebase(repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_df = load_knowledge('knowledge_df.csv')\n",
    "client = openai.OpenAI()\n",
    "assistant = client.beta.assistants.retrieve(os.getenv('OPENAI_ASSISTANT_ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset thread\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assembling context\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'codebase_input\\\\ecf-srdf-service-file-to-image\\\\src\\\\convertor_doc_2_pdf.py>ClassDef>FunctionDef'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Please write unit tests for the function 'validate_input_file' in file-to-image\\src\\convertor_doc_2_pdf.py, which checks if the file exists and if it has a supported extension.\"\n",
    "k=8\n",
    "#response = handle_user_query(tosend, knowledge_df, client, thread, k=8)\n",
    "print(\"assembling context\")\n",
    "ctx = get_top_k_context(knowledge_df, query, k)\n",
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"adding question to assistant thread\")\n",
    "ask_assistant(query, ctx, client, thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"telling assistant to think\")\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=os.getenv('OPENAI_ASSISTANT_ID')\n",
    ")\n",
    "print(\"waiting for assistant to respond\")\n",
    "sec=0\n",
    "while run.status != 'completed':\n",
    "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "    time.sleep(1)\n",
    "    #print with carriage return that the program is still waiting\n",
    "    print(f\"Waiting...{sec}\", end='\\r')\n",
    "    sec+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"assistant responded\")\n",
    "response = client.beta.threads.messages.list(thread_id=thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To write a full unit test for a `validate_input_file` function in the \"file-to-image\" service, first, we need to clarify the exact behavior and structure of this function, as it is not explicitly detailed in the provided context. Assuming `validate_input_file` is a function that validates the input file path, ensuring it is a valid file and not a directory, and potentially performs other checks relevant to the \"file-to-image\" service, I will proceed with an outline for a unit test in Python using the `unittest` library.\n",
      "\n",
      "If the `validate_input_file` function follows this hypothetical behavior, the unit test could include tests for:\n",
      "- Verifying the function accepts a path leading to a file and returns some form of positive confirmation (true, valid, etc.)\n",
      "- Verifying the function rejects a path that leads to a directory, throwing an exception or returning a specific response indicating invalid input.\n",
      "- Verifying the function rejects a non-existing path with the appropriate error or indication.\n",
      "\n",
      "Here is an example of how the code for these unit tests could look:\n",
      "\n",
      "```python\n",
      "import unittest\n",
      "from unittest.mock import patch\n",
      "from your_service_module import validate_input_file\n",
      "import os\n",
      "\n",
      "class TestValidateInputFile(unittest.TestCase):\n",
      "\n",
      "    def setUp(self):\n",
      "        self.existing_file_path = \"existing_file.txt\"\n",
      "        self.non_existing_file_path = \"non_existing_file.txt\"\n",
      "        self.directory_path = \"existing_directory\"\n",
      "        # Set up for the test, like creating a temporary file or directory if needed\n",
      "        with open(self.existing_file_path, 'w') as f:\n",
      "            f.write(\"This is a test file.\")\n",
      "\n",
      "        if not os.path.exists(self.directory_path):\n",
      "            os.makedirs(self.directory_path)\n",
      "\n",
      "    def tearDown(self):\n",
      "        # Clean up after tests\n",
      "        if os.path.exists(self.existing_file_path):\n",
      "            os.remove(self.existing_file_path)\n",
      "        if os.path.exists(self.directory_path):\n",
      "            os.rmdir(self.directory_path)\n",
      "\n",
      "    def test_validate_input_file_with_valid_file(self):\n",
      "        # Test the case where the path is to a valid existing file\n",
      "        result = validate_input_file(self.existing_file_path)\n",
      "        self.assertTrue(result)\n",
      "\n",
      "    def test_validate_input_file_with_directory(self):\n",
      "        # Test the case where the path is to a directory, should raise an exception or return False\n",
      "        with self.assertRaises(Exception) as context:\n",
      "            validate_input_file(self.directory_path)\n",
      "        \n",
      "        # Alternatively, if your function returns False or specific message instead of raising an exception:\n",
      "        # result = validate_input_file(self.directory_path)\n",
      "        # self.assertFalse(result)\n",
      "\n",
      "    def test_validate_input_file_with_non_existing_path(self):\n",
      "        # Test the case where the path does not exist\n",
      "        with self.assertRaises(Exception) as context:\n",
      "            validate_input_file(self.non_existing_file_path)\n",
      "        \n",
      "        # Alternatively, if your function returns False or specific message instead of raising an exception:\n",
      "        # result = validate_input_file(self.non_existing_file_path)\n",
      "        # self.assertFalse(result)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    unittest.main()\n",
      "```\n",
      "Please note that your actual implementation of `validate_input_file` might differ, thus requiring adjustments to the unit test code above. Specifically, you need to replace `your_service_module` with the actual Python module where `validate_input_file` is defined. Additionally, the behavior on how `validate_input_file` handles different scenarios (valid file, directory, non-existing path) might necessitate changes in the assertion methods used in the unit tests.\n"
     ]
    }
   ],
   "source": [
    "print(response.data[0].content[0].text.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
